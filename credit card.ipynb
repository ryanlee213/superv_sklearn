{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ryan\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style='ticks')\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred = pd.read_csv('../../creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([284315,    492], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(cred.Class.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    284315\n",
       "1       492\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cred.groupby('Class').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ryan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "cred['Amount_norm'] = StandardScaler().fit_transform(cred['Amount'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cred.drop(['Time', 'Class', 'Amount'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
       "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount_norm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l = list(range(0, len(X.columns))) # rename columns to numbers\n",
    "X = X.rename(columns=dict(zip(X.columns, l))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = cred.Class.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,cross_val_score, cross_validate\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,precision_score,classification_report,f1_score \n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN, RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train, X_test, y_Train, y_test = train_test_split(X, y, random_state=0, test_size=0.1)\n",
    "\n",
    "# test set is set right here (in future, test is validation, and vice versa)\n",
    "# resample THEN get val set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversample\n",
    "X_ovrsamp, y_ovrsamp = SMOTE(random_state=0).fit_sample(X_Train, y_Train)\n",
    "X_ovrsamp1, y_ovrsamp1 = SMOTE(kind='borderline1', random_state=0).fit_sample(X_Train, y_Train)\n",
    "X_ovrsamp2, y_ovrsamp2 = SMOTE(kind='borderline2', random_state=0).fit_sample(X_Train, y_Train)\n",
    "X_ovrsampada, y_ovrsampada = ADASYN(random_state=0).fit_sample(X_Train, y_Train)\n",
    "X_ovrsamprand, y_ovrsamprand = RandomOverSampler(random_state=0).fit_sample(X_Train, y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = [X_ovrsamp, y_ovrsamp]\n",
    "smote1 = [X_ovrsamp1, y_ovrsamp1]\n",
    "smote2 = [X_ovrsamp2, y_ovrsamp2]\n",
    "smoteada = [X_ovrsampada, y_ovrsampada]\n",
    "smoterand = [X_ovrsamprand, y_ovrsamprand]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regularization \n",
    "c_params = [0.001, 0.01, 0.1, 1, 10, 100, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrcv = LogisticRegressionCV(Cs=c_params, random_state=777, scoring='recall')\n",
    "lrcv_1 = LogisticRegressionCV(Cs=c_params, random_state=777, scoring='recall')\n",
    "lrcv_2 = LogisticRegressionCV(Cs=c_params, random_state=777, scoring='recall')\n",
    "lrcv_ada = LogisticRegressionCV(Cs=c_params, random_state=777, scoring='recall')\n",
    "lrcv_rand = LogisticRegressionCV(Cs=c_params, random_state=777, scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using smote, for example\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_ovrsamp, y_ovrsamp, random_state=0, test_size=0.1) # smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-set Class balance: [28426    55] \n",
      "Validation-set Class balance: [25640 25538] \n",
      "Train-set Class balance: [230249 230351]\n"
     ]
    }
   ],
   "source": [
    "print('Test-set Class balance:' ,np.bincount(y_test),\n",
    "     '\\nValidation-set Class balance:' , np.bincount(y_val),\n",
    "     '\\nTrain-set Class balance:', np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg(lrclf, X_resample, y_resample, X_test, y_test):\n",
    "    '''train_test_split X_resample, y_resample;\n",
    "        fit to resulting train set;\n",
    "        cross_validate - print(accuracy, precision, recall, f1, roc_auc);\n",
    "        '''\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_resample, y_resample, random_state=0, test_size=0.1)\n",
    "\n",
    "    lrclf.fit(X_train, y_train)  \n",
    "    \n",
    "    print('-------------------------------------------')\n",
    "    print('CV')\n",
    "    print('-------------------------------------------')    \n",
    "    scoring = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "    scores = cross_validate(lrclf, X_train, y_train, cv=3, scoring=scoring, return_train_score=False)\n",
    "    \n",
    "    for metric in scoring:\n",
    "        metr = 'test_' + metric\n",
    "        print(metric, scores[metr])\n",
    "        \n",
    "    print('-------------------------------------------')\n",
    "    print('Overall')\n",
    "    print('-------------------------------------------')\n",
    "    \n",
    "\n",
    "    y_ = lrclf.predict(X_val)\n",
    "    print(confusion_matrix(y_val, y_))\n",
    "    print('Validation - Recall: %0.4f'% recall_score(y_val,y_), \n",
    "          'Precision: %0.4f'% precision_score(y_val,y_),\n",
    "          'Accuracy: %0.4f'% lrclf.score(X_val,y_val))\n",
    "    \n",
    "    y_ = lrclf.predict(X_test)\n",
    "    print(confusion_matrix(y_test, y_))\n",
    "    print('Test - Recall: %0.4f'% recall_score(y_test,y_), \n",
    "          'Precision: %0.4f'% precision_score(y_test,y_),\n",
    "          'Accuracy: %0.4f'% lrclf.score(X_test,y_test))\n",
    "    \n",
    "    \n",
    "    \n",
    "        # hold off on below\n",
    "\n",
    "#     fpr, tpr, thresholds = roc_curve(y_val, y_)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "#     plt.title('Receiver Operating Characteristic')\n",
    "#     plt.plot(fpr, tpr, 'b',label='AUC = %0.4f'% roc_auc)\n",
    "#     plt.legend(loc='lower right')\n",
    "#     plt.plot([0,1],[0,1],'r--')\n",
    "#     plt.xlim([-0.1,1.0])\n",
    "#     plt.ylim([-0.1,1.01])\n",
    "#     plt.ylabel('True Positive Rate')\n",
    "#     plt.xlabel('False Positive Rate')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "CV\n",
      "-------------------------------------------\n",
      "accuracy [0.94298331 0.94356299 0.94317797]\n",
      "precision [0.97393134 0.97532622 0.97279611]\n",
      "recall [0.91035893 0.9101766  0.91188154]\n",
      "f1 [0.94107273 0.94162585 0.94135441]\n",
      "roc_auc [0.98765004 0.98775369 0.98770225]\n",
      "-------------------------------------------\n",
      "Overall\n",
      "-------------------------------------------\n",
      "[[24980   660]\n",
      " [ 2283 23255]]\n",
      "Validation - Recall: 0.9106 Precision: 0.9724 Accuracy: 0.9425\n",
      "[[27723   703]\n",
      " [    2    53]]\n",
      "Test - Recall: 0.9636 Precision: 0.0701 Accuracy: 0.9752\n"
     ]
    }
   ],
   "source": [
    "log_reg(lrcv, X_ovrsamp, y_ovrsamp, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "CV\n",
      "-------------------------------------------\n",
      "accuracy [0.98800266 0.98857582 0.98772243]\n",
      "precision [0.9885525  0.98977753 0.98878824]\n",
      "recall [0.9874453  0.98735414 0.98663767]\n",
      "f1 [0.98799859 0.98856435 0.98771178]\n",
      "roc_auc [0.99871126 0.99885559 0.99872952]\n",
      "-------------------------------------------\n",
      "Overall\n",
      "-------------------------------------------\n",
      "[[25358   282]\n",
      " [  350 25188]]\n",
      "Validation - Recall: 0.9863 Precision: 0.9889 Accuracy: 0.9877\n",
      "[[28145   281]\n",
      " [    5    50]]\n",
      "Test - Recall: 0.9091 Precision: 0.1511 Accuracy: 0.9900\n"
     ]
    }
   ],
   "source": [
    "log_reg(lrcv_1, X_ovrsamp1, y_ovrsamp1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "CV\n",
      "-------------------------------------------\n",
      "accuracy [0.98379512 0.9837885  0.98328036]\n",
      "precision [0.98377892 0.98501731 0.98402714]\n",
      "recall [0.98380456 0.98251466 0.9825014 ]\n",
      "f1 [0.98379174 0.98376439 0.98326368]\n",
      "roc_auc [0.99797792 0.99810702 0.99801365]\n",
      "-------------------------------------------\n",
      "Overall\n",
      "-------------------------------------------\n",
      "[[25126   413]\n",
      " [  462 25177]]\n",
      "Validation - Recall: 0.9820 Precision: 0.9839 Accuracy: 0.9829\n",
      "[[28001   425]\n",
      " [    4    51]]\n",
      "Test - Recall: 0.9273 Precision: 0.1071 Accuracy: 0.9849\n"
     ]
    }
   ],
   "source": [
    "log_reg(lrcv_2, X_ovrsamp2, y_ovrsamp2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "CV\n",
      "-------------------------------------------\n",
      "accuracy [0.87582636 0.87592976 0.87463933]\n",
      "precision [0.89496598 0.89462169 0.89072308]\n",
      "recall [0.85158408 0.85223542 0.85404427]\n",
      "f1 [0.87273625 0.87291432 0.87199814]\n",
      "roc_auc [0.95420418 0.95478347 0.95364578]\n",
      "-------------------------------------------\n",
      "Overall\n",
      "-------------------------------------------\n",
      "[[22984  2594]\n",
      " [ 3665 21935]]\n",
      "Validation - Recall: 0.8568 Precision: 0.8942 Accuracy: 0.8777\n",
      "[[25583  2843]\n",
      " [    0    55]]\n",
      "Test - Recall: 1.0000 Precision: 0.0190 Accuracy: 0.9002\n"
     ]
    }
   ],
   "source": [
    "log_reg(lrcv_ada, X_ovrsampada, y_ovrsampada, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using ADASYN oversampling results in the best recall_score\n",
    "# however, not true for validation set\n",
    "## why would a model with a lower score in the validation set be selected?? \n",
    "### regardless if it did result in the better recall_score for the test set\n",
    "### the real-world test set would be the actual implementation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_g = DecisionTreeClassifier(max_depth=5, random_state=0, criterion='gini')\n",
    "dt_e = DecisionTreeClassifier(max_depth=5, random_state=0, criterion='entropy')\n",
    "\n",
    "rfc_g = RandomForestClassifier(max_depth=5, random_state=0, criterion='gini')\n",
    "rfc_e = RandomForestClassifier(max_depth=5, random_state=0, criterion='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trees_and_forests(clf, ovr_samp):\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(ovr_samp[0], ovr_samp[1], random_state=0, test_size=0.1)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    " \n",
    "    y_v = clf.predict(X_val)\n",
    "    y_t = clf.predict(X_test) \n",
    "    print('Original features\\n')\n",
    "    print(confusion_matrix(y_val, y_v), \n",
    "      'Validation: score=%0.4f' % clf.score(X_val, y_val), '  recall=%0.4f' % recall_score(y_val, y_v), '  precision=%0.4f\\n\\n' % precision_score(y_val, y_v),\n",
    "      confusion_matrix(y_test, y_t), \n",
    "      'Test: score=%0.4f' % clf.score(X_test, y_test), '  recall=%0.4f' % recall_score(y_test, y_t), '  precision=%0.4f' % precision_score(y_test, y_t),\n",
    "     )\n",
    "    \n",
    "    clf_coef = pd.DataFrame(clf.feature_importances_)\n",
    "    clf_feats = clf_coef[clf_coef[0]>0.01].sort_values(0, ascending=False)\n",
    "    clf_index = clf_feats.index.values\n",
    "    \n",
    "    \n",
    "    print('\\nThe most important features: ', clf_index)\n",
    "    print('\\n\\nImportant features\\n')\n",
    "    \n",
    "    # train, val, test set with only key features\n",
    "    X_train_key_feat = pd.DataFrame(X_train)[clf_index]\n",
    "    X_val_key_feat  = pd.DataFrame(X_val)[clf_index]\n",
    "    X_test_key_feat = pd.DataFrame(X_test)[clf_index]\n",
    "    \n",
    "    clf.fit(X_train_key_feat, y_train)\n",
    "    \n",
    "    y_kf_v = clf.predict(X_val_key_feat)\n",
    "    y_kf_t = clf.predict(X_test_key_feat)\n",
    "    \n",
    "    print(confusion_matrix(y_val, y_kf_v), \n",
    "      'Validation: score=%0.4f' % clf.score(X_val_key_feat, y_val), '  recall=%0.4f' % recall_score(y_val, y_kf_v), '  precision=%0.4f\\n\\n' % precision_score(y_val, y_kf_v),\n",
    "      confusion_matrix(y_test, y_kf_t), \n",
    "      'Test: score=%0.4f' % clf.score(X_test_key_feat, y_test), '  recall=%0.4f' % recall_score(y_test, y_kf_t), '  precision=%0.4f' % precision_score(y_test, y_kf_t),\n",
    "     )  \n",
    "\n",
    "    return clf_index # maybe return other stuff as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features\n",
      "\n",
      "[[24349  1291]\n",
      " [ 1304 24234]] Validation: score=0.9493   recall=0.9489   precision=0.9494\n",
      "\n",
      " [[27011  1415]\n",
      " [    3    52]] Test: score=0.9502   recall=0.9455   precision=0.0354\n",
      "\n",
      "The most important features:  [13  3  7 28  9]\n",
      "\n",
      "\n",
      "Important features\n",
      "\n",
      "[[24971   669]\n",
      " [ 2115 23423]] Validation: score=0.9456   recall=0.9172   precision=0.9722\n",
      "\n",
      " [[27739   687]\n",
      " [    6    49]] Test: score=0.9757   recall=0.8909   precision=0.0666\n"
     ]
    }
   ],
   "source": [
    "list_dtg0 = trees_and_forests(dt_g, smote);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features\n",
      "\n",
      "[[25123   517]\n",
      " [ 2594 22944]] Validation: score=0.9392   recall=0.8984   precision=0.9780\n",
      "\n",
      " [[27901   525]\n",
      " [    8    47]] Test: score=0.9813   recall=0.8545   precision=0.0822\n",
      "\n",
      "The most important features:  [13  3  7  9 28]\n",
      "\n",
      "\n",
      "Important features\n",
      "\n",
      "[[25269   371]\n",
      " [ 2753 22785]] Validation: score=0.9390   recall=0.8922   precision=0.9840\n",
      "\n",
      " [[28081   345]\n",
      " [    7    48]] Test: score=0.9876   recall=0.8727   precision=0.1221\n"
     ]
    }
   ],
   "source": [
    "list_dte0 = trees_and_forests(dt_e, smote);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features\n",
      "\n",
      "[[25517   123]\n",
      " [ 2742 22796]] Validation: score=0.9440   recall=0.8926   precision=0.9946\n",
      "\n",
      " [[28284   142]\n",
      " [    7    48]] Test: score=0.9948   recall=0.8727   precision=0.2526\n",
      "\n",
      "The most important features:  [13 11 16  9  3  6  8 20 10  5  2]\n",
      "\n",
      "\n",
      "Important features\n",
      "\n",
      "[[25357   283]\n",
      " [ 2746 22792]] Validation: score=0.9408   recall=0.8925   precision=0.9877\n",
      "\n",
      " [[28155   271]\n",
      " [    5    50]] Test: score=0.9903   recall=0.9091   precision=0.1558\n"
     ]
    }
   ],
   "source": [
    "list_rfcg0 = trees_and_forests(rfc_g, smote);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features\n",
      "\n",
      "[[25561    79]\n",
      " [ 2949 22589]] Validation: score=0.9408   recall=0.8845   precision=0.9965\n",
      "\n",
      " [[28357    69]\n",
      " [    7    48]] Test: score=0.9973   recall=0.8727   precision=0.4103\n",
      "\n",
      "The most important features:  [13 11  3  9 16  6  8 20 10  1  7  2]\n",
      "\n",
      "\n",
      "Important features\n",
      "\n",
      "[[25537   103]\n",
      " [ 2857 22681]] Validation: score=0.9422   recall=0.8881   precision=0.9955\n",
      "\n",
      " [[28329    97]\n",
      " [    8    47]] Test: score=0.9963   recall=0.8545   precision=0.3264\n"
     ]
    }
   ],
   "source": [
    "list_rfce0 = trees_and_forests(rfc_e, smote);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features\n",
      "\n",
      "[[25283   357]\n",
      " [   57 25481]] Validation: score=0.9919   recall=0.9978   precision=0.9862\n",
      "\n",
      " [[28010   416]\n",
      " [    5    50]] Test: score=0.9852   recall=0.9091   precision=0.1073\n",
      "\n",
      "The most important features:  [13 11  3  0 24 16]\n",
      "\n",
      "\n",
      "Important features\n",
      "\n",
      "[[25206   434]\n",
      " [   59 25479]] Validation: score=0.9904   recall=0.9977   precision=0.9833\n",
      "\n",
      " [[27945   481]\n",
      " [    4    51]] Test: score=0.9830   recall=0.9273   precision=0.0959\n"
     ]
    }
   ],
   "source": [
    "list_dtg1 = trees_and_forests(dt_g, smote1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features\n",
      "\n",
      "[[25228   412]\n",
      " [   44 25494]] Validation: score=0.9911   recall=0.9983   precision=0.9841\n",
      "\n",
      " [[28022   404]\n",
      " [    4    51]] Test: score=0.9857   recall=0.9273   precision=0.1121\n",
      "\n",
      "The most important features:  [13  3 11  9 10 28 25]\n",
      "\n",
      "\n",
      "Important features\n",
      "\n",
      "[[25233   407]\n",
      " [   64 25474]] Validation: score=0.9908   recall=0.9975   precision=0.9843\n",
      "\n",
      " [[28025   401]\n",
      " [    4    51]] Test: score=0.9858   recall=0.9273   precision=0.1128\n"
     ]
    }
   ],
   "source": [
    "list_dte1 = trees_and_forests(dt_e, smote1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features\n",
      "\n",
      "[[25450   190]\n",
      " [  315 25223]] Validation: score=0.9901   recall=0.9877   precision=0.9925\n",
      "\n",
      " [[28220   206]\n",
      " [    8    47]] Test: score=0.9925   recall=0.8545   precision=0.1858\n",
      "\n",
      "The most important features:  [13  3 16  2 11  9  6 18 15 20  0 17  1 10 23]\n",
      "\n",
      "\n",
      "Important features\n",
      "\n",
      "[[25447   193]\n",
      " [  503 25035]] Validation: score=0.9864   recall=0.9803   precision=0.9923\n",
      "\n",
      " [[28238   188]\n",
      " [    6    49]] Test: score=0.9932   recall=0.8909   precision=0.2068\n"
     ]
    }
   ],
   "source": [
    "list_rfcg1 = trees_and_forests(rfc_g, smote1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features\n",
      "\n",
      "[[25467   173]\n",
      " [  235 25303]] Validation: score=0.9920   recall=0.9908   precision=0.9932\n",
      "\n",
      " [[28244   182]\n",
      " [    8    47]] Test: score=0.9933   recall=0.8545   precision=0.2052\n",
      "\n",
      "The most important features:  [13  3  9  2 11 16 18  1 15  6 23 17  0]\n",
      "\n",
      "\n",
      "Important features\n",
      "\n",
      "[[25393   247]\n",
      " [  237 25301]] Validation: score=0.9905   recall=0.9907   precision=0.9903\n",
      "\n",
      " [[28138   288]\n",
      " [    7    48]] Test: score=0.9896   recall=0.8727   precision=0.1429\n"
     ]
    }
   ],
   "source": [
    "list_rfce1 = trees_and_forests(rfc_e, smote1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features\n",
      "\n",
      "[[25069   470]\n",
      " [  330 25309]] Validation: score=0.9844   recall=0.9871   precision=0.9818\n",
      "\n",
      " [[27870   556]\n",
      " [    5    50]] Test: score=0.9803   recall=0.9091   precision=0.0825\n",
      "\n",
      "The most important features:  [13  3 11 16  0]\n",
      "\n",
      "\n",
      "Important features\n",
      "\n",
      "[[24908   631]\n",
      " [  397 25242]] Validation: score=0.9799   recall=0.9845   precision=0.9756\n",
      "\n",
      " [[27745   681]\n",
      " [    5    50]] Test: score=0.9759   recall=0.9091   precision=0.0684\n"
     ]
    }
   ],
   "source": [
    "list_dtg2 = trees_and_forests(dt_g, smote2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features\n",
      "\n",
      "[[24986   553]\n",
      " [  263 25376]] Validation: score=0.9841   recall=0.9897   precision=0.9787\n",
      "\n",
      " [[27770   656]\n",
      " [    4    51]] Test: score=0.9768   recall=0.9273   precision=0.0721\n",
      "\n",
      "The most important features:  [13  3  9 16 11]\n",
      "\n",
      "\n",
      "Important features\n",
      "\n",
      "[[25243   296]\n",
      " [  830 24809]] Validation: score=0.9780   recall=0.9676   precision=0.9882\n",
      "\n",
      " [[28117   309]\n",
      " [    4    51]] Test: score=0.9890   recall=0.9273   precision=0.1417\n"
     ]
    }
   ],
   "source": [
    "list_dte2 = trees_and_forests(dt_e, smote2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features\n",
      "\n",
      "[[25225   314]\n",
      " [  359 25280]] Validation: score=0.9868   recall=0.9860   precision=0.9877\n",
      "\n",
      " [[28073   353]\n",
      " [    6    49]] Test: score=0.9874   recall=0.8909   precision=0.1219\n",
      "\n",
      "The most important features:  [13  3  9  2 11 16  1  6 18  0 20 23]\n",
      "\n",
      "\n",
      "Important features\n",
      "\n",
      "[[25143   396]\n",
      " [  360 25279]] Validation: score=0.9852   recall=0.9860   precision=0.9846\n",
      "\n",
      " [[27975   451]\n",
      " [    5    50]] Test: score=0.9840   recall=0.9091   precision=0.0998\n"
     ]
    }
   ],
   "source": [
    "list_rfcg2 = trees_and_forests(rfc_g, smote2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features\n",
      "\n",
      "[[25201   338]\n",
      " [  388 25251]] Validation: score=0.9858   recall=0.9849   precision=0.9868\n",
      "\n",
      " [[28041   385]\n",
      " [    5    50]] Test: score=0.9863   recall=0.9091   precision=0.1149\n",
      "\n",
      "The most important features:  [13  3  9 16  2 11 17  6 23 18  0  1 15  4 10]\n",
      "\n",
      "\n",
      "Important features\n",
      "\n",
      "[[25236   303]\n",
      " [  550 25089]] Validation: score=0.9833   recall=0.9785   precision=0.9881\n",
      "\n",
      " [[28093   333]\n",
      " [    6    49]] Test: score=0.9881   recall=0.8909   precision=0.1283\n"
     ]
    }
   ],
   "source": [
    "list_rfce2 = trees_and_forests(rfc_e, smote2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features\n",
      "\n",
      "[[22552  3026]\n",
      " [ 1809 23791]] Validation: score=0.9055   recall=0.9293   precision=0.8872\n",
      "\n",
      " [[25134  3292]\n",
      " [    4    51]] Test: score=0.8843   recall=0.9273   precision=0.0153\n",
      "\n",
      "The most important features:  [ 3 13 28  7  2  6 19  0  8]\n",
      "\n",
      "\n",
      "Important features\n",
      "\n",
      "[[22452  3126]\n",
      " [ 1839 23761]] Validation: score=0.9030   recall=0.9282   precision=0.8837\n",
      "\n",
      " [[25016  3410]\n",
      " [    4    51]] Test: score=0.8801   recall=0.9273   precision=0.0147\n"
     ]
    }
   ],
   "source": [
    "list_dtgada = trees_and_forests(dt_g, smoteada);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features\n",
      "\n",
      "[[23098  2480]\n",
      " [ 4730 20870]] Validation: score=0.8591   recall=0.8152   precision=0.8938\n",
      "\n",
      " [[25749  2677]\n",
      " [    5    50]] Test: score=0.9058   recall=0.9091   precision=0.0183\n",
      "\n",
      "The most important features:  [13  3 11  7  0  9 25 18 16]\n",
      "\n",
      "\n",
      "Important features\n",
      "\n",
      "[[23089  2489]\n",
      " [ 4730 20870]] Validation: score=0.8589   recall=0.8152   precision=0.8934\n",
      "\n",
      " [[25739  2687]\n",
      " [    3    52]] Test: score=0.9056   recall=0.9455   precision=0.0190\n"
     ]
    }
   ],
   "source": [
    "list_dteada = trees_and_forests(dt_e, smoteada);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features\n",
      "\n",
      "[[24172  1406]\n",
      " [ 3196 22404]] Validation: score=0.9101   recall=0.8752   precision=0.9409\n",
      "\n",
      " [[26888  1538]\n",
      " [    1    54]] Test: score=0.9460   recall=0.9818   precision=0.0339\n",
      "\n",
      "The most important features:  [13  3 11 16  9  6  2  0 19 18 20  4 17  7  1 28]\n",
      "\n",
      "\n",
      "Important features\n",
      "\n",
      "[[24004  1574]\n",
      " [ 2893 22707]] Validation: score=0.9127   recall=0.8870   precision=0.9352\n",
      "\n",
      " [[26702  1724]\n",
      " [    2    53]] Test: score=0.9394   recall=0.9636   precision=0.0298\n"
     ]
    }
   ],
   "source": [
    "list_rfcgada = trees_and_forests(rfc_g, smoteada);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features\n",
      "\n",
      "[[24253  1325]\n",
      " [ 3342 22258]] Validation: score=0.9088   recall=0.8695   precision=0.9438\n",
      "\n",
      " [[26964  1462]\n",
      " [    3    52]] Test: score=0.9486   recall=0.9455   precision=0.0343\n",
      "\n",
      "The most important features:  [13  3 16 11  9  6 18  0  7 19 17 15 28 20  4  2 25 23]\n",
      "\n",
      "\n",
      "Important features\n",
      "\n",
      "[[23732  1846]\n",
      " [ 2988 22612]] Validation: score=0.9055   recall=0.8833   precision=0.9245\n",
      "\n",
      " [[26437  1989]\n",
      " [    2    53]] Test: score=0.9301   recall=0.9636   precision=0.0260\n"
     ]
    }
   ],
   "source": [
    "list_rfceada = trees_and_forests(rfc_e, smoteada);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_smote = np.hstack([list_dtg0, list_dte0, list_rfcg0, list_rfce0])\n",
    "list_smote1 = np.hstack([list_dtg1, list_dte1, list_rfcg1, list_rfce1])\n",
    "list_smote2 = np.hstack([list_dtg2, list_dte2, list_rfcg2, list_rfce2])\n",
    "list_smoteada = np.hstack([list_dtgada, list_dteada, list_rfcgada, list_rfceada])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_feature(list_feat):\n",
    "    values, counts = np.unique(list_feat, return_counts=True)\n",
    "    max_occ = np.max(counts) # max number of occurence\n",
    "    freq_feat = np.argwhere(counts==max_occ) # index of max_occ \n",
    "    features = np.ndarray.flatten(values[freq_feat])\n",
    "    \n",
    "    return features\n",
    "\n",
    "# tbh, this method seems like it could potentially be overfitting;\n",
    "## as the features that show up most often are selected,\n",
    "### but a feature that shows up most often could have just barely shown up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_features = good_feature(list_smote)\n",
    "smote1_features = good_feature(list_smote1)\n",
    "smote2_features = good_feature(list_smote2)\n",
    "smoteada_features = good_feature(list_smoteada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "CV\n",
      "-------------------------------------------\n",
      "accuracy [0.93248401 0.93242539 0.93261991]\n",
      "precision [0.97070246 0.97100586 0.97011123]\n",
      "recall [0.89191759 0.89150083 0.89277574]\n",
      "f1 [0.92964381 0.92955643 0.92983824]\n",
      "roc_auc [0.97887998 0.97911586 0.97917339]\n",
      "-------------------------------------------\n",
      "Overall\n",
      "-------------------------------------------\n",
      "[[24928   712]\n",
      " [ 2760 22778]]\n",
      "Validation - Recall: 0.8919 Precision: 0.9697 Accuracy: 0.9322\n",
      "[[27696   730]\n",
      " [    4    51]]\n",
      "Test - Recall: 0.9273 Precision: 0.0653 Accuracy: 0.9742\n"
     ]
    }
   ],
   "source": [
    "log_reg(lrcv, pd.DataFrame(X_ovrsamp)[smote_features], y_ovrsamp, pd.DataFrame(X_test[smote_features]), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "CV\n",
      "-------------------------------------------\n",
      "accuracy [0.9725989  0.97354983 0.97219472]\n",
      "precision [0.97855702 0.97973481 0.97866554]\n",
      "recall [0.96638623 0.96711554 0.96544808]\n",
      "f1 [0.97243354 0.97338428 0.97201188]\n",
      "roc_auc [0.99691078 0.99717831 0.99681731]\n",
      "-------------------------------------------\n",
      "Overall\n",
      "-------------------------------------------\n",
      "[[25064   576]\n",
      " [  907 24631]]\n",
      "Validation - Recall: 0.9645 Precision: 0.9771 Accuracy: 0.9710\n",
      "[[27832   594]\n",
      " [    4    51]]\n",
      "Test - Recall: 0.9273 Precision: 0.0791 Accuracy: 0.9790\n"
     ]
    }
   ],
   "source": [
    "log_reg(lrcv_1, pd.DataFrame(X_ovrsamp1)[smote1_features], y_ovrsamp1, pd.DataFrame(X_test)[smote1_features], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "CV\n",
      "-------------------------------------------\n",
      "accuracy [0.97046257 0.96999342 0.96964802]\n",
      "precision [0.97248139 0.97326126 0.97244832]\n",
      "recall [0.9683127  0.96652769 0.96667058]\n",
      "f1 [0.97039257 0.96988279 0.96955084]\n",
      "roc_auc [0.99500219 0.99518638 0.9949349 ]\n",
      "-------------------------------------------\n",
      "Overall\n",
      "-------------------------------------------\n",
      "[[24831   708]\n",
      " [  827 24812]]\n",
      "Validation - Recall: 0.9677 Precision: 0.9723 Accuracy: 0.9700\n",
      "[[27657   769]\n",
      " [    4    51]]\n",
      "Test - Recall: 0.9273 Precision: 0.0622 Accuracy: 0.9729\n"
     ]
    }
   ],
   "source": [
    "log_reg(lrcv_2, pd.DataFrame(X_ovrsamp2)[smote2_features], y_ovrsamp2, pd.DataFrame(X_test)[smote2_features], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "CV\n",
      "-------------------------------------------\n",
      "accuracy [0.83442212 0.83303373 0.83249204]\n",
      "precision [0.86304625 0.86184201 0.86005502]\n",
      "recall [0.79498202 0.79321036 0.79419773]\n",
      "f1 [0.82761707 0.82610318 0.82581545]\n",
      "roc_auc [0.91686074 0.91655789 0.91588142]\n",
      "-------------------------------------------\n",
      "Overall\n",
      "-------------------------------------------\n",
      "[[22285  3293]\n",
      " [ 5141 20459]]\n",
      "Validation - Recall: 0.7992 Precision: 0.8614 Accuracy: 0.8352\n",
      "[[24897  3529]\n",
      " [    1    54]]\n",
      "Test - Recall: 0.9818 Precision: 0.0151 Accuracy: 0.8761\n"
     ]
    }
   ],
   "source": [
    "log_reg(lrcv_ada, pd.DataFrame(X_ovrsampada)[smoteada_features], y_ovrsampada, pd.DataFrame(X_test)[smoteada_features], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop  here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse balance\n",
    "\n",
    "## initial results showed promise, however\n",
    "## intuitively, what is the sense of doing this?\n",
    "### in the regular imbalance, there was heavy bias towards the majority class\n",
    "### would not reversing the imbalance create bias towards the \"minority class\"\n",
    "#### there are already other methods of doing some form of this\n",
    "##### i.e., using predict_proba, lowering threshold for classification\n",
    "#### is there evidence/reasoning reversed imbalance does not work or is not used?\n",
    "##### bit unorthodox to say the least, or maybe it isn't\n",
    "\n",
    "# HOWEVER, must test for each combination of undersampling/oversampling method\n",
    "## may just use ClusterCentroid and ADASYN\n",
    "### have to extract PCs first\n",
    "\n",
    "# AND how to determine what ratio to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useless(?) stuff below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_balance(X_Train, y_Train, underSamp_model, ovrSamp_model, underSamp_ratio=0.005):\n",
    "   \n",
    "    ratio1 = np.bincount(y_Train)[1]\n",
    "    ratio0 = (ratio1 / underSamp_ratio) - ratio1 # underSamp_ratio arbitrary; \n",
    "    # original ratio = 0.0017\n",
    "    X_unsamp, y_unsamp = underSamp_model(random_state=0, ratio={0:ratio0, 1:ratio1}).fit_sample(X_Train, y_Train)\n",
    "    X_ovrsamp, y_ovrsamp = ovrSamp_model[0], ovrSamp_model[1]\n",
    "    \n",
    "    \n",
    "    df_ovr = pd.DataFrame(X_ovrsamp)\n",
    "    df_ovr['Class'] = y_ovrsamp\n",
    "\n",
    "    df_under = pd.DataFrame(X_unsamp)\n",
    "    df_under['Class'] = y_unsamp\n",
    "\n",
    "    df_ovr1 = df_ovr[df_ovr.Class==1]\n",
    "    df_under0 = df_under[df_under.Class==0]\n",
    "    \n",
    "    df_invrs_bal = pd.concat([df_ovr1, df_under0]).reset_index()\n",
    "    inv_bal_index = df_invrs_bal['index'] # in case index is needed\n",
    "    \n",
    "    df = df_invrs_bal.drop('index', 1) \n",
    "    \n",
    "    \n",
    "    X_train = df.iloc[:, :-1] # column '28' is 'Amount' \n",
    "    y_train = df['Class'].copy()\n",
    "    \n",
    "    \n",
    "    lrcv = LogisticRegressionCV(Cs=c_params, random_state=777, scoring='recall')\n",
    "    lrcv.fit(X_train, y_train)\n",
    "    y_ = lrcv.predict(X_test) # can call global variables?\n",
    "    \n",
    "    print('Accuracy %0.4f'% lrcv.score(X_test, y_test), '\\nConfusion Matrix %0.4'% confusion_matrix(y_test, y_), \n",
    "          'Recall %0.4f'% recall_score(y_test, y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler, ClusterCentroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_unsamp, y_unsamp = RandomUnderSampler(random_state=0, ratio={0:86167, 1:433}).fit_sample(X_Train, y_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.bincount(y_Train), np.bincount(y_unsamp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine y_ovrsamp where 'Class' = 1 with\n",
    "# with y_unsamp where 'Class' = 0\n",
    "## must join to respective X_matrix first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ovr = pd.DataFrame(X_ovrsamp)\n",
    "df_ovr['Class'] = y_ovrsamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ovr = pd.DataFrame(X_ovrsamp)\n",
    "df_ovr['Class'] = y_ovrsamp\n",
    "\n",
    "df_under = pd.DataFrame(X_unsamp)\n",
    "df_under['Class'] = y_unsamp\n",
    "\n",
    "df_ovr1 = df_ovr[df_ovr.Class==1]\n",
    "df_under0 = df_under[df_under.Class==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ovr1 = df_ovr[df_ovr.Class==1]\n",
    "df_under0 = df_under[df_under.Class==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (np.bincount(df_under0.Class), np.bincount(df_ovr1.Class) ) \n",
    "# reversed the imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_invrs_bal = pd.concat([df_ovr1, df_under0]).reset_index()\n",
    "inv_bal_index = df_invrs_bal['index'] # in case index is needed\n",
    "df0 = df_invrs_bal.drop('index', 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X0 = df0.iloc[:, :-1] # column '28' is 'Amount' \n",
    "y0 = df0['Class'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrcv0 = LogisticRegressionCV(Cs=c_params, random_state=777, scoring='recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrcv0.fit(X0, y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrcv0.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_0 = lrcv0.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, y_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check y_test index for relationship with errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrcv.fit(X_ovrsamp, y_ovrsamp)\n",
    "lrcv_1.fit(X_ovrsamp1, y_ovrsamp1)\n",
    "lrcv_2.fit(X_ovrsamp2, y_ovrsamp2)\n",
    "lrcv_ada.fit(X_ovrsampada, y_ovrsampada)\n",
    "lrcv_rand.fit(X_ovrsamprand, y_ovrsamprand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# done prior to addition of X_val, y_val\n",
    "# keep test or use val?\n",
    "\n",
    "y_ada = lrcv_ada.predict(X_test)\n",
    "y_0 = lrcv.predict(X_test) # regular smote\n",
    "y_1 = lrcv_1.predict(X_test) # smote borderline 1\n",
    "y_2 = lrcv_2.predict(X_test) \n",
    "y_rand = lrcv_rand.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indices = []\n",
    "Y = pd.DataFrame(y_test, columns=['Class'])\n",
    "for y_ in [y_ada, y_0, y_1, y_2, y_rand]:\n",
    "    fn = Y[y_ != y_test] # all incorrect predictions\n",
    "    type2 = fn[fn['Class']==1].index.values # only type 2 \n",
    "    indices.append(type2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c, d, e = indices # there isn't too much difference in type 2 errors\n",
    "\n",
    "np.in1d(a,b).sum() # other sampling methods provide similar methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = ['smote', 'smote_borderline1', 'smote_bordeline2', 'ADASYN', 'Random_over_samp']\n",
    "# clfs = [lrcv, lrcv_1, lrcv_2, lrcv_ada, lrcv_rand]\n",
    "# samps = [smote, smote1, smote2, smoteada, smoterand]\n",
    "\n",
    "# for name, model, samp in zip(names, clfs, samps):\n",
    "#     model.fit(samp[0], samp[1]) # samp[0] == X; samp[1] == y for each \n",
    "#     y_ = model.predict(X)\n",
    "#     mat = confusion_matrix(y, y_)\n",
    "#     print('Entire set\\n')\n",
    "#     print('\\t', name)\n",
    "#     print(mat)\n",
    "#     print('\\t\\tRecall: %0.4f'% recall_score(y,y_), \n",
    "#           'Precision: %0.4f'% precision_score(y,y_),\n",
    "#           'Accuracy: %0.4f\\n'% model.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = ['smote', 'smote_borderline1', 'smote_bordeline2', 'ADASYN', 'Random_over_samp']\n",
    "# clfs = [lrcv, lrcv_1, lrcv_2, lrcv_ada, lrcv_rand]\n",
    "# samps = [smote, smote1, smote2, smoteada, smoterand]\n",
    "\n",
    "# for name, model, samp in zip(names, clfs, samps):\n",
    "#     model.fit(samp[0], samp[1]) # samp[0] == X; samp[1] == y for each \n",
    "#     y_ = model.predict(X_test)\n",
    "#     mat = confusion_matrix(y_test, y_)\n",
    "#     print('Test Set\\n')\n",
    "#     print('\\t', name)\n",
    "#     print(mat)\n",
    "#     print('\\t\\tRecall: %0.4f'% recall_score(y_test,y_), \n",
    "#           'Precision: %0.4f'% precision_score(y_test,y_),\n",
    "#           'Accuracy: %0.4f\\n'% model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useless stuff above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression assumptions with uniform distribution\n",
    "## convert uniform to normal\n",
    "### bin mapping, has to be equal range?\n",
    "\n",
    "# pca transform in order of explained_variance_?\n",
    "\n",
    "# trees, class_weight parameter corrects imbalance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
